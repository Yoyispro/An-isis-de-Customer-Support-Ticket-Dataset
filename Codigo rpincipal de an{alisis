import pandas as pd


file_path = '/content/customer_support_tickets.csv'
data = pd.read_csv(file_path)

# Mostrar las primeras filas y la información del DataFrame
data.head(), data.info(), data.describe(include='all')


import re
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from nltk import download

# Descargar recursos de nltk
download('stopwords')
download('wordnet')
download('omw-1.4')

# Función para preprocesar el texto
def preprocess_text(text):
    # Convertir texto a minúsculas
    text = text.lower()
    
    # Remover caracteres no alfabéticos
    text = re.sub(r'[^a-zA-Z\s]', '', text)
    
    # Tokenización por espacios
    tokens = text.split()
    
    # Remover stopwords
    stop_words = set(stopwords.words('english'))
    tokens = [word for word in tokens if word not in stop_words]
    
    # Lematización
    lemmatizer = WordNetLemmatizer()
    tokens = [lemmatizer.lemmatize(word) for word in tokens]
    
    # Reunir tokens en una cadena
    return ' '.join(tokens)

# Aplicar la función de preprocesamiento a la columna 'Ticket Description'
data['Cleaned Description'] = data['Ticket Description'].apply(preprocess_text)

data[['Ticket Description', 'Cleaned Description']].head()


import matplotlib.pyplot as plt

# Crear un gráfico de pastel para la distribución de 'Ticket Type'
ticket_type_counts = data['Ticket Type'].value_counts()

plt.figure(figsize=(8, 6))
plt.pie(ticket_type_counts, labels=ticket_type_counts.index, autopct='%1.1f%%', startangle=140)
plt.title('Distribución de Tipos de Tickets')
plt.axis('equal')  # Asegurar que se dibuje un círculo
plt.show()

# Gráfico de barras para productos que generan más tickets
product_counts = data['Product Purchased'].value_counts()

plt.figure(figsize=(12, 8))
product_counts.plot(kind='bar', color='skyblue')
plt.title('Frecuencia de Tickets por Producto')
plt.xlabel('Producto')
plt.ylabel('Cantidad de Tickets')
plt.xticks(rotation=45)
plt.show()

# Histograma para la distribución de edad de los clientes
plt.figure(figsize=(10, 8))
plt.hist(data['Customer Age'], bins=20, color='green', alpha=0.7)
plt.title('Distribución de Edad de los Clientes')
plt.xlabel('Edad')
plt.ylabel('Cantidad de Tickets')
plt.grid(True)
plt.show()


from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import TruncatedSVD

# Crear una matriz de términos-documentos usando TF-IDF
vectorizer = TfidfVectorizer(max_features=1000)  # Limitar a 1000 términos para gestionar la dimensionalidad
tfidf_matrix = vectorizer.fit_transform(data['Cleaned Description'])

# Usar SVD para realizar LSA. El número de tópicos 'k' se elige como 10 inicialmente para una exploración general
k = 10
lsa_model = TruncatedSVD(n_components=k)
lsa_topic_matrix = lsa_model.fit_transform(tfidf_matrix)

# Explorar los términos más importantes para cada tópico
terms = vectorizer.get_feature_names_out()
topic_terms = {}
for i, comp in enumerate(lsa_model.components_):
    terms_comp = zip(terms, comp)
    sorted_terms = sorted(terms_comp, key=lambda x: x[1], reverse=True)
    topic_terms["Topic " + str(i)] = [t[0] for t in sorted_terms[:10]]

topic_terms


from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

# Calcular la matriz de correlación de coseno de los tópicos
cosine_matrix = cosine_similarity(lsa_model.components_)

# Crear un DataFrame para una visualización más clara de la matriz de correlación
cosine_df = pd.DataFrame(cosine_matrix, columns=["Topic " + str(i) for i in range(k)], index=["Topic " + str(i) for i in range(k)])

# Mostrar la matriz de correlación
cosine_df


# Calcular la frecuencia de cada tópico en los documentos
topic_frequencies = np.argmax(lsa_topic_matrix, axis=1)
topic_counts = pd.Series(topic_frequencies).value_counts().sort_index()

# Crear un gráfico de barras para mostrar la frecuencia de cada tópico
plt.figure(figsize=(10, 6))
topic_counts.plot(kind='bar', color='teal')
plt.title('Frecuencia de Tópicos en los Tickets')
plt.xlabel('Tópico')
plt.ylabel('Frecuencia')
plt.xticks(rotation=0)
plt.grid(axis='y', linestyle='--')
plt.show()


from wordcloud import WordCloud

# Función para generar y mostrar nubes de palabras para cada tópico
def plot_word_clouds(topic_terms_dict):
    rows = (len(topic_terms_dict) + 1) // 2
    plt.figure(figsize=(14, rows * 6))
    
    for i, (topic, words) in enumerate(topic_terms_dict.items(), 1):
        wc = WordCloud(width=400, height=300, background_color='white').generate(" ".join(words))
        plt.subplot(rows, 2, i)
        plt.imshow(wc, interpolation='bilinear')
        plt.title(f'Word Cloud for {topic}')
        plt.axis('off')
    
    plt.tight_layout()
    plt.show()

# Generar y mostrar nubes de palabras para los tópicos
plot_word_clouds(topic_terms)


# Generar nuevamente el gráfico de pastel para 'Ticket Type'
plt.figure(figsize=(14, 6))

# Primer gráfico: Ticket Type
plt.subplot(1, 2, 1)
plt.pie(ticket_type_counts, labels=ticket_type_counts.index, autopct='%1.1f%%', startangle=140)
plt.title('Distribución de Tipos de Tickets')
plt.axis('equal')

# Segundo gráfico: Frecuencia de Tópicos
plt.subplot(1, 2, 2)
plt.pie(topic_counts, labels=topic_counts.index, autopct='%1.1f%%', startangle=140)
plt.title('Distribución de Tópicos')
plt.axis('equal')

plt.tight_layout()
plt.show()
